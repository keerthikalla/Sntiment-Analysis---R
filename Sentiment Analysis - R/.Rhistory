library(tidyverse)
library(skimr)
library(janitor)
library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)
library(readxl)
library(lubridate)
library(wordcloud)
library(tm)
library(corrplot)
library(SnowballC)
# Importing and loading our dataset:
covid19_tweets <- read.csv("C:/Users/KEERTHI/Desktop/MINI PROJECT/covid19_tweets.csv", comment.char="#")
View(covid19_tweets)
df1 <- read_csv("C:/Users/KEERTHI/Desktop/MINI PROJECT/covid19_tweets.csv")
# Discovering the dataset:
str(df1)
skim(df1)
head(df1)
dim(df1)
colnames(df1)
# Replacing of Null values
df1$user_location[which(is.na(df1$user_location))] <-"undetermined "
df1$user_description[which(is.na(df1$user_description))] <-"undetermined"
df1$source[which(is.na(df1$source))] <-"undetermined "
df1$hashtags[which(is.na(df1$hashtags))] <-"undetermined "
any((is.na(df1)))
sum(duplicated(df1))
# Changing the data type and create a column for the day, month, and year for the date of the Tweet:
month<-format(as.Date(df1$date, format = "%Y/%m/%d"), "%m")
year<-format(as.Date(df1$date, format = "%Y/%m/%d"), "%Y")
days<-format(as.Date(df1$date, format = "%Y/%m/%d"), "%d")
ddf1 <- cbind(df1,days,month,year)
# Plotting a bar graph to show activity amongst tweets
ddf1 %>%
count(date) %>%
ggplot(aes(x = date, y= n)) +
geom_bar(stat = "identity") +
ylab("# tweets") + xlab("Date") +
ggtitle(" Activity in 2020") + theme_classic()
gro_month <- ddf1 %>%
group_by(month) %>%
ddf1 %>%
count(date) %>%
ggplot(aes(x = date, y= n)) +
geom_bar(stat = "identity") +
ylab("# tweets") + xlab("Date") +
ggtitle(" Activity in 2020") + theme_classic()
ddf1 %>%
count(date) %>%
ggplot(aes(x = date, y= n)) +
geom_bar(stat = "identity") +
ylab("# tweets") + xlab("Date") +
ggtitle(" Activity in 2020") + theme_classic()
# Displaying top 2 months of tweets
gro_month <- ddf1 %>%
group_by(month) %>%
summarise(Number_of_tweet=n())
barplot(gro_month$Number_of_tweet,
main = " showing the top months of tweets in 2020", names.arg = c("7:July","8:August"),
col=c( "#E7B800", "#FC4E07") )
ddf1 %>%
count(date) %>%
ggplot(aes(x = date, y= n)) +
geom_bar(stat = "identity") +
ylab("# tweets") + xlab("Date") +
ggtitle(" Activity in 2020") + theme_classic()
# Top 10 active members
ddf1 %>%
unnest(user_name) %>%
count(user_name, sort = TRUE) %>%
top_n(n = 14, n)%>%
ggplot( aes(x=reorder(user_name,-n), y=n )) +
geom_bar(stat = "identity")+
labs(x="user name", y="count") +
ggtitle("Top 14 Most Active Members in term of # of tweets  ")+ coord_flip()+ theme_classic()
# Top 10 origin of tweets
ddf1 %>%
filter(user_location !="undetermined ")%>%
unnest(user_location) %>%
count(user_location, sort = TRUE) %>%
top_n(n = 14, n)%>%
ggplot( aes(x=reorder(user_location,-n), y=n)) +
geom_bar(stat = "identity")+
labs(x="Locations", y="count") +
ggtitle("The top 10 Locations of tweets ")+ coord_flip()+theme_classic()
# Top 14 hashtags used in tweets
ddf1 %>% filter(hashtags !="undetermined ")%>%
unnest(hashtags) %>%
count(hashtags, sort = TRUE) %>%
top_n(n = 14, n)%>%
ggplot( aes(x=reorder(hashtags,-n), y=n)) +
geom_bar(stat = "identity")+
labs(x="hashtags", y="count") +
ggtitle("Hastags Used in Tweets ")+ coord_flip()+ theme_classic()
# Creating of Wordcloud
tweetsDS.Corpus<-Corpus(VectorSource(ddf1$text))
tweetsDS.Clean<-tm_map(tweetsDS.Corpus, PlainTextDocument)
tweetsDS.Clean<-tm_map(tweetsDS.Corpus,removeWords,stopwords())
tweetsDS.Clean<-tm_map(tweetsDS.Corpus,tolower)
tweetsDS.Clean<-tm_map(tweetsDS.Clean,removeNumbers)
tweetsDS.Clean<-tm_map(tweetsDS.Clean,removeWords,stopwords("english"))
tweetsDS.Clean<-tm_map(tweetsDS.Clean,removePunctuation)
tweetsDS.Clean<-tm_map(tweetsDS.Clean,stripWhitespace)
tweetsDS.Clean<-tm_map(tweetsDS.Clean,stemDocument)
set.seed(142)
wordcloud(words = tweetsDS.Clean, min.freq = 500,colors=brewer.pal(8, "Set2"),random.order=FALSE)
#--------------word cloud is our desired final output--------------
